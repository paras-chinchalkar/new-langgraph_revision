{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c08292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PARAS\\Downloads\\agentic-ai-langraph\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from  typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders  import TextLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d38ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fbdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "model=ChatGroq(model=\"openai/gpt-oss-120b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bad17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"HI\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6557418",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=TextLoader(\"research_notes.txt\",encoding=\"utf-8\").load()\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "chunk=splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f71abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 622.65it/s, Materializing param=pooler.dense.weight]                        \n",
      "\u001b[1mMPNetModel LOAD REPORT\u001b[0m from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings()\n",
    "vectorstore=FAISS.from_documents(chunk,embedding=embeddings)\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676e2e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define AGENT STATE \n",
    "class IterativeRagState(BaseModel):\n",
    "    question:str\n",
    "\n",
    "    refined_questions:str=\"\"\n",
    "    retrieve_docs:List[Document]=[]\n",
    "    answer:str=\"\"\n",
    "    verified:bool= False\n",
    "    attempts:int=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a73ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieveing the node earlier formed\n",
    "def retrieved_node(state:IterativeRagState)->IterativeRagState:\n",
    "    query=state.refined_questions or state.question\n",
    "    docs=retriever.invoke(query)\n",
    "    return state.model_copy(update={\"retrieved_docs\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d11f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate node\n",
    "def GenerateNode(state:IterativeRagState)->IterativeRagState:\n",
    "    context=\"\\n\\n\".join(doc.page_content for doc in state.retrieve_docs)\n",
    "    prompt=f\"\"\"Use the follwing context to answer the follwing question\n",
    "    \n",
    "    Context:{context}\n",
    "    \n",
    "    Question:{state.question}\n",
    "    \"\"\"\n",
    "    response=model.invoke(prompt.strip()).content.strip()\n",
    "    return state.model_copy(update={\"answer\":response,\"attempts\":state.attempts+1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6336902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_on_answer(state:IterativeRagState)->IterativeRagState:\n",
    "    prompt=f\"\"\"\n",
    "    Evaluate wheather the answer below is factually sufficient ans complete\n",
    "    question:{state.question}\n",
    "    answer:{state.answer}\n",
    "    Respond \"Yes\" if it is  completed otherwise NO with feedback\n",
    "    \"\"\"\n",
    "    feedback=model.invoke(prompt).content.lower()\n",
    "    verified=\"yes\" in feedback\n",
    "    return state.model_copy(update={\"verified\":verified})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb83826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_query(state:IterativeRagState)->IterativeRagState:\n",
    "    prompt=f\"\"\"\n",
    "    The answer appears incomplete Suggested a better version of the query that wpuld help retrieved more relevant Content\n",
    "    Question:{state.question}\n",
    "    Answer:{state.answer}\n",
    "\n",
    "    \"\"\"\n",
    "    new_query=model.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"refined_question\":new_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268dd9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23002a3b7d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder=StateGraph(IterativeRagState)\n",
    "builder.add_node(\"retrieve\",retrieved_node)\n",
    "builder.add_node(\"answer\",GenerateNode)\n",
    "builder.add_node(\"reflect\",reflect_on_answer)\n",
    "builder.add_node(\"refine\",refine_query)\n",
    "\n",
    "builder.set_entry_point(\"retrieve\")\n",
    "builder.add_edge(\"retrieve\",\"answer\")\n",
    "builder.add_edge(\"answer\",\"reflect\")\n",
    "builder.add_conditional_edges(\"reflect\", lambda s:END if s.verified or s.attempts >=2 else \"refine\")\n",
    "\n",
    "builder.add_edge(\"refine\",\"retrieve\")\n",
    "builder.add_edge(\"answer\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693c0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c082acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000023080017AD0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6dfab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer ### Agent Loops with Transformer‑Based Systems  \n",
      "\n",
      "Transformer‑based language models (e.g., GPT‑4, LLaMA, Claude) are exceptionally good at generating natural‑language output, reasoning, and even code.  When you embed such a model inside an **agent loop**, the model becomes a “thinking” component that repeatedly:\n",
      "\n",
      "1. **Observes** the current state of the environment (text, API responses, sensor data, etc.).\n",
      "2. **Decides** what to do next (ask a question, call a tool, modify internal state, etc.).\n",
      "3. **Acts** by invoking a tool, sending a command, or producing a final answer.\n",
      "4. **Receives feedback** (the tool’s result, an error, or a new observation) and loops back to step 1.\n",
      "\n",
      "This pattern is often called a **“reason‑act‑observe”** or **“plan‑execute‑observe”** loop.  It lets a single LLM behave like a flexible, multi‑step problem‑solver rather than a one‑shot text generator.\n",
      "\n",
      "Below is a concise guide covering the core concepts, common architectures, practical implementation tips, and pitfalls to watch out for.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Core Concepts\n",
      "\n",
      "| Concept | What it means for a transformer‑based agent |\n",
      "|---------|----------------------------------------------|\n",
      "| **Prompt (or “Thought”)** | The textual context you feed the model each turn. It usually contains: <br>• The task description <br>• A **scratch‑pad** where the model can write reasoning steps <br>• A **tool‑use schema** (list of available actions) <br>• The latest observation/result |\n",
      "| **Action** | A structured token (often JSON) that tells the orchestrator which tool to call and with what arguments. Example: `{\"action\":\"search\",\"query\":\"latest COVID‑19 vaccine efficacy\"}`\n",
      "| **Observation** | The raw output returned from the executed action (search results, database rows, API JSON, etc.). It is fed back into the next prompt. |\n",
      "| **Termination condition** | The model signals it is done, usually with a special token or a `final_answer` field. |\n",
      "| **Self‑reflection** | The model can request to “think again” or “revise” its plan if the observation looks unexpected. |\n",
      "| **Tool‑use policies** | Guardrails (e.g., rate limits, safety filters) that decide whether a proposed action is allowed. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Popular Agent Loop Architectures\n",
      "\n",
      "| Architecture | Key Paper / Repo | Main Idea |\n",
      "|--------------|------------------|-----------|\n",
      "| **ReAct** (Reason + Act) | *“ReAct: Synergizing Reasoning and Acting in Language Models”* (2023) | The model writes a **reasoning trace** (`Thought:`) followed by an **action** (`Action:`). The orchestrator parses the action, executes it, and feeds the result back. |\n",
      "| **Self‑Ask** | *“Self‑Ask: A Prompting Strategy for Multi‑Hop Reasoning”* (2022) | The model asks itself sub‑questions (`Q:`) and then looks up answers (`A:`). The loop continues until a final answer is produced. |\n",
      "| **Toolformer** | *“Toolformer: Language Models Can Teach Themselves to Use Tools”* (2023) | The model is **fine‑tuned** to predict when to insert a tool call token. The loop is implicit; the model decides during generation. |\n",
      "| **LLM‑Planner / LLM‑Executor** | OpenAI’s **function calling** + **retrieval** pipelines | The model emits a **function call** JSON; the runtime executes the function and returns the result as a new user message. |\n",
      "| **AutoGPT / BabyAGI** | Community‑driven repos (2023‑2024) | The agent maintains a **task list** and a **memory store**; each loop picks the highest‑priority task, calls tools, and updates the list. |\n",
      "| **Chain‑of‑Thought (CoT) + Tool Use** | CoT prompting + explicit tool schema | The model reasons step‑by‑step (CoT) and can interleave tool calls whenever it says “**Tool:**”. |\n",
      "\n",
      "All of these follow the same high‑level loop:\n",
      "\n",
      "```\n",
      "while not done:\n",
      "    prompt = build_prompt(state, tools_schema, last_observation)\n",
      "    output = LLM.generate(prompt)\n",
      "    action, thought, final_answer = parse(output)\n",
      "    if action:\n",
      "        observation = run_tool(action)\n",
      "        state = update(state, action, observation)\n",
      "    else:\n",
      "        done = True\n",
      "        return final_answer\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Detailed Walk‑through of a Minimal ReAct‑style Loop\n",
      "\n",
      "Below is a **pseudo‑code** example that works with any OpenAI‑compatible API.  Replace `LLM` with your favorite transformer endpoint.\n",
      "\n",
      "```python\n",
      "import json, time, requests\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 1️⃣ Define the toolset (you can expose any function you like)\n",
      "# ----------------------------------------------------------------------\n",
      "TOOLS = {\n",
      "    \"search\": {\n",
      "        \"description\": \"Run a web search and return the top snippet.\",\n",
      "        \"parameters\": {\"type\": \"object\",\n",
      "                       \"properties\": {\"query\": {\"type\": \"string\"}},\n",
      "                       \"required\": [\"query\"]},\n",
      "        \"func\": lambda query: web_search_api(query)   # your own wrapper\n",
      "    },\n",
      "    \"calculator\": {\n",
      "        \"description\": \"Evaluate a mathematical expression.\",\n",
      "        \"parameters\": {\"type\": \"object\",\n",
      "                       \"properties\": {\"expr\": {\"type\": \"string\"}},\n",
      "                       \"required\": [\"expr\"]},\n",
      "        \"func\": lambda expr: eval(expr)  # safe eval library recommended\n",
      "    }\n",
      "}\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 2️⃣ Prompt template (keeps a scratch‑pad)\n",
      "# ----------------------------------------------------------------------\n",
      "SYSTEM_PROMPT = \"\"\"You are an autonomous reasoning agent. Follow the pattern:\n",
      "\n",
      "Thought: <your reasoning>\n",
      "Action: <JSON with \"action\" and \"action_input\">\n",
      "Observation: <result of the action>\n",
      "\n",
      "When you have enough information, output:\n",
      "\n",
      "Answer: <final answer>\n",
      "\n",
      "Only use the actions listed in the schema. If you think no action is needed, directly output the Answer.\"\"\"\n",
      "\n",
      "def build_user_prompt(history, last_observation=None):\n",
      "    # History is a list of dicts: {\"role\":\"assistant\",\"content\":...}\n",
      "    # Append the most recent observation as a user message so the model sees it.\n",
      "    messages = [{\"role\":\"system\",\"content\":SYSTEM_PROMPT}]\n",
      "    messages += history\n",
      "    if last_observation is not None:\n",
      "        messages.append({\"role\":\"user\",\"content\":f\"Observation: {last_observation}\"})\n",
      "    return messages\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "# 3️⃣ Core loop\n",
      "# ----------------------------------------------------------------------\n",
      "def run_agent(user_query, max_iters=10):\n",
      "    history = [{\"role\":\"user\",\"content\":user_query}]\n",
      "    observation = None\n",
      "\n",
      "    for i in range(max_iters):\n",
      "        msgs = build_user_prompt(history, observation)\n",
      "        response = openai.ChatCompletion.create(\n",
      "            model=\"gpt-4o-mini\",\n",
      "            messages=msgs,\n",
      "            temperature=0.0,   # deterministic for tool use\n",
      "        )\n",
      "        assistant_msg = response[\"choices\"][0][\"message\"][\"content\"]\n",
      "        history.append({\"role\":\"assistant\",\"content\":assistant_msg})\n",
      "\n",
      "        # ---- Parse the assistant output ---------------------------------\n",
      "        if \"Answer:\" in assistant_msg:\n",
      "            # Final answer reached\n",
      "            answer = assistant_msg.split(\"Answer:\",1)[1].strip()\n",
      "            return answer, history\n",
      "\n",
      "        # Extract the JSON after \"Action:\"\n",
      "        try:\n",
      "            action_json = assistant_msg.split(\"Action:\",1)[1].strip().split(\"\\n\")[0]\n",
      "            action_dict = json.loads(action_json)\n",
      "        except Exception as e:\n",
      "            # If parsing fails, ask the model to re‑format\n",
      "            history.append({\"role\":\"assistant\",\n",
      "                            \"content\":\"I couldn't parse my own action. Please rewrite it as valid JSON.\"})\n",
      "            continue\n",
      "\n",
      "        # ---- Execute the requested tool ---------------------------------\n",
      "        action_name = action_dict.get(\"action\")\n",
      "        action_input = action_dict.get(\"action_input\", {})\n",
      "\n",
      "        if action_name not in TOOLS:\n",
      "            observation = f\"Error: unknown action '{action_name}'.\"\n",
      "        else:\n",
      "            try:\n",
      "                observation = TOOLS[action_name][\"func\"](**action_input)\n",
      "            except Exception as e:\n",
      "                observation = f\"Error while executing {action_name}: {e}\"\n",
      "\n",
      "        # Loop back – the next iteration will feed the observation.\n",
      "    raise RuntimeError(\"Maximum iterations exceeded without reaching an answer.\")\n",
      "```\n",
      "\n",
      "**Key points in the code:**\n",
      "\n",
      "* **Deterministic generation** (`temperature=0.0`) reduces the chance of malformed JSON.\n",
      "* **System prompt** explicitly tells the model the *Thought → Action → Observation* pattern.\n",
      "* **Parsing** is defensive: if the model mis‑formats JSON, we ask it to correct itself.\n",
      "* **Tool schema** can be exposed to the model via the `function` parameter (OpenAI) or via an in‑prompt list; both work.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Practical Tips & Best Practices\n",
      "\n",
      "| Area | Recommendation |\n",
      "|------|----------------|\n",
      "| **Prompt engineering** | • Keep the *scratch‑pad* short (≤ 2000 tokens) to avoid context overflow.<br>• Use explicit markers (`Thought:`, `Action:`, `Observation:`) and **never** rely on natural language alone for parsing.<br>• Provide a short **tool description** in the system prompt. |\n",
      "| **Safety** | • Whitelist only the tools you intend to expose.<br>• Sanitize arguments (e.g., use a safe math evaluator, rate‑limit web searches).<br>• Run a secondary LLM or rule‑based filter on the generated `Action` JSON before execution. |\n",
      "| **Error handling** | • If a tool fails, feed the **error message** back as the next observation. The model can then decide to retry, modify the query, or abort.<br>• Implement a **max‑iteration** guard (typically 5‑10 steps). |\n",
      "| **State management** | • Keep a **structured memory** (e.g., a dict of key‑value pairs) that you pass to the model each turn. This is useful for multi‑turn tasks like “plan a trip”.<br>• For longer tasks, consider a vector store to retrieve relevant past observations. |\n",
      "| **Tool selection** | • Start with a **small, well‑defined toolset** (search, calculator, database query). <br>• Add more complex tools (code execution, image generation) only after the basic loop is stable. |\n",
      "| **Evaluation** | • Use **unit tests** that mock tool responses and assert that the final answer matches expectations.<br>• Log the full conversation (prompt → output → observation) for debugging. |\n",
      "| **Scalability** | • When many concurrent agents run, share a **tool worker pool** (e.g., a microservice) rather than invoking the tool directly from the loop. |\n",
      "| **Fine‑tuning vs. prompting** | • For most use‑cases, a well‑crafted prompt (as above) suffices.<br>• If you need higher reliability, consider **fine‑tuning** a smaller model on a dataset of *Thought‑Action‑Observation* triples (the “Toolformer” approach). |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Common Pitfalls & How to Avoid Them\n",
      "\n",
      "| Pitfall | Symptom | Fix |\n",
      "|---------|---------|-----|\n",
      "| **Malformed JSON** | The parser throws `json.JSONDecodeError`. | Use `temperature=0` and a *strict* system prompt. If it still happens, add a “re‑format” sub‑loop (ask the model to rewrite the action). |\n",
      "| **Infinite loops** | The agent keeps calling the same tool with identical input. | Detect repeated `(action, input)` pairs and break with an error. Also enforce a max‑iteration limit. |\n",
      "| **Hallucinated tool names** | Model outputs `\"action\":\"search_web\"` when only `\"search\"` exists. | Include an explicit **enumerated list** of actions in the system prompt and enforce a whitelist before execution. |\n",
      "| **Tool latency** | Overall response time > several seconds. | Run tools **asynchronously** and pre‑fetch likely results (e.g., cache recent web searches). |\n",
      "| **Context overflow** | Prompt exceeds model’s token limit after many steps. | Summarize older observations (e.g., “Earlier you searched X and got Y”) or store them in a vector DB and retrieve only the most relevant. |\n",
      "| **Safety breach** | Model tries to run arbitrary shell commands or fetch disallowed URLs. | Use a sandboxed execution environment and filter URLs against a blocklist. |\n",
      "| **Unclear termination** | Model never emits `Answer:` but keeps “thinking”. | Add a secondary “controller” that, after N steps, forces a final answer by prompting the model with “You have used all your tools; give your best answer now.” |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Extending the Loop: Multi‑Tool & Hierarchical Agents\n",
      "\n",
      "1. **Hierarchical planning** – A *manager* LLM produces a high‑level plan (list of subtasks). Each subtask is handed to a *worker* agent that runs its own ReAct loop. The manager can re‑order or prune tasks based on worker feedback.\n",
      "\n",
      "2. **Memory‑augmented agents** – Store observations in a **vector store** (e.g., Pinecone, Chroma). At each turn, retrieve the top‑k most relevant memories and prepend them to the prompt. This enables reasoning over thousands of past steps.\n",
      "\n",
      "3. **Self‑consistency** – Run the loop **multiple times** with different random seeds, collect all final answers, and aggregate (majority vote, confidence weighting). This reduces variance in the answer.\n",
      "\n",
      "4. **Tool‑learning** – Use the **Toolformer** approach: let the model *suggest* new tool calls during pre‑training, then fine‑tune on the successful ones. Over time the model learns when a tool is useful, reducing the need for explicit prompting.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. Quick Reference Cheat‑Sheet\n",
      "\n",
      "| Component | Example Syntax (in the LLM’s output) |\n",
      "|-----------|----------------------------------------|\n",
      "| **Thought** | `Thought: I need the current price of Bitcoin to answer the question.` |\n",
      "| **Action** | `Action: {\"action\":\"search\",\"action_input\":{\"query\":\"Bitcoin price USD March 2024\"}}` |\n",
      "| **Observation** | (Provided by orchestrator) `Observation: Bitcoin is $57,800 as of 2024‑03‑12.` |\n",
      "| **Final Answer** | `Answer: The current price of Bitcoin is $57,800.` |\n",
      "| **Error handling** | `Observation: Error – search API returned 429 Too Many Requests.` |\n",
      "| **Re‑try** | `Thought: The rate limit hit; I will retry with a narrower query.` |\n",
      "| **Termination guard** | After 7 iterations, orchestrator injects: `System: You have used all allowed steps. Provide your best answer now.` |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Sample End‑to‑End Interaction\n",
      "\n",
      "**User:** “What is the total cost of a round‑trip flight from New York to Tokyo in June 2025, including taxes?”\n",
      "\n",
      "**Agent Loop (excerpt):**\n",
      "\n",
      "| Turn | Model Output | Action Executed | Observation |\n",
      "|------|--------------|-----------------|-------------|\n",
      "| 1 | `Thought: I need flight prices. Action: {\"action\":\"search\",\"action_input\":{\"query\":\"NYC to Tokyo round‑trip June 2025 price\"}}` | Calls search API | `Observation: Average price $1,200, range $950‑$1,450.` |\n",
      "| 2 | `Thought: I need tax info for international flights. Action: {\"action\":\"search\",\"action_input\":{\"query\":\"US international flight taxes 2025\"}}` | Calls search API | `Observation: US imposes a 7.5% security fee + $50 airport fee per segment.` |\n",
      "| 3 | `Thought: Compute total cost. Action: {\"action\":\"calculator\",\"action_input\":{\"expr\":\"1200 * 1.075 + 2*50\"}}` | Runs calculator | `Observation: $1,340.` |\n",
      "| 4 | `Answer: The estimated total cost for a round‑trip NYC‑Tokyo flight in June 2025, including taxes and fees, is about **$1,340**.` | – | – |\n",
      "\n",
      "The loop terminates after the model emits `Answer:`.\n",
      "\n",
      "---\n",
      "\n",
      "## 9. TL;DR Summary\n",
      "\n",
      "* **Agent loops** turn a transformer LLM into an autonomous reasoning system by repeatedly: *think → act → observe*.\n",
      "* The loop is driven by a **structured prompt** that forces the model to output **Thought**, **Action (JSON)**, and **Observation** tokens.\n",
      "* A **toolset** (search, calculator, DB query, code executor, etc.) is exposed; the orchestrator parses the action, runs the tool, and feeds the result back.\n",
      "* Keep temperature low, enforce a whitelist, and guard against infinite loops.\n",
      "* Use **system prompts**, **JSON schemas**, and **defensive parsing** to make the loop robust.\n",
      "* Extend with memory stores, hierarchical planners, or self‑consistency for more complex tasks.\n",
      "\n",
      "With these patterns you can build agents that reliably solve multi‑step problems, browse the web, run calculations, and even execute code—all powered by a transformer‑based language model. Happy building!\n",
      "Verfied True\n"
     ]
    }
   ],
   "source": [
    "query=\"agent loops with transformer based systems\"\n",
    "initial_system=IterativeRagState(question=query,)\n",
    "final=graph.invoke(initial_system)\n",
    "print(\"Final Answer\",final['answer'])\n",
    "print(\"Verfied\",final['verified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad3ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
